target: modules.gpt.GPT
params:
    vocab_size: 8192
    block_size: 348  # = 256 + 92 = dim(vqgan_latent_space,16x16) + dim(conditional_builder.embedding_dim)
    n_layer: 24
    n_head: 12
    emb_size: 1056
    embd_pdrop: 0.1
    resid_pdrop: 0.1
    attn_pdrop: 0.1